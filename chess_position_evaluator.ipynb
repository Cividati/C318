{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-QvR6AmkEN2"
      },
      "source": [
        "# Avaliador de Posições de Xadrez\n",
        "\n",
        "O xadrez tem sido uma referência clássica para inteligência artificial, aprendizado de máquinas e mineração de dados desde sua criação. Devido às simples regras determinísticas do xadrez aliadas às possibilidades exponenciais e difíceis de avaliar posições, ganhou o foco de muitos pesquisadores em Ciência da Computação. Hoje em dia, existem vários IAs de xadrez sofisticados que competem em um nível acima até mesmo do mais forte Grande Mestre de xadrez do mundo. Enquanto as máquinas de xadrez como Stockfish (do qual este conjunto de dados é baseado) e AlphaGo são muito complexas para tentar competir aqui, vamos ver se podemos usar as avaliações de Stockfish para construir uma função de avaliação de posição comparável.\n",
        "\n",
        "Para este projeto estarei usando a biblioteca de pytorch e construindo com ela uma Rede Neural."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEBD3tVxksVF",
        "outputId": "890346a9-8851-4e25-8d2b-473acfb808f4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hyeeXkQXkEN4"
      },
      "outputs": [],
      "source": [
        "# pytorch libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# for visualizing the results\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# for reading input data\n",
        "import pandas as pd\n",
        "\n",
        "# for parsing the FEN of chess positions\n",
        "import re\n",
        "\n",
        "# Measuring time in seconds:\n",
        "\n",
        "from timeit import default_timer as timer\n",
        "from datetime import timedelta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAOmdyUIkEN5"
      },
      "source": [
        "Para representar uma posição de xadrez, é comum usar [Forsyth-Edwards Notation (FEN)](http://https://en.wikipedia.org/wiki/Forsyth%E2%80%93Edwards_Notation) que contém todas as informações necessárias para reconstruir um jogo de xadrez a partir da posição atual. Para tornar estas informações utilizáveis para uma rede neural, usaremos um byte para representar se uma peça específica (torre branca, cavaleiro branco, etc...) está em um quadrado específico no tabuleiro de xadrez 8x8. Como há 6 peças diferentes e dois jogadores diferentes, isso significa que há 12 peças específicas que poderiam estar potencialmente em cada quadrado. \n",
        "\n",
        "No entanto, ainda precisamos manter um registro de informações como de quem é a vez, quais opções de castling ainda são legais, se en passant é possível, quantas meias jogadas desde uma jogada de peão ou captura de peças, e quantas jogadas o jogo já teve. Para fazer isso, usamos um tabuleiro adicional 8x8 onde as posições das torres representam direitos de castling, a 3ª e 6ª posições (fileira) mantêm registro de possíveis jogadas en passant, os e1 e e8 representam quem está em movimento, e a 4ª e 5ª posições representam o número de meias jogadas e jogadas completas como números binários (máximo possível é 255), respectivamente.\n",
        "\n",
        "Abaixo está uma função para fazer esta conversão."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-G2KNRQkEN6"
      },
      "outputs": [],
      "source": [
        "def fen_to_bit_vector(fen):\n",
        "    # piece placement - lowercase for black pieces, uppercase for white pieces. numbers represent consequtive spaces. / represents a new row \n",
        "    # active color - whose turn it is, either 'w' or 'b'\n",
        "    # castling rights - which castling moves are still legal K or k for kingside and Q or q for queenside, '-' if no legal castling moves for either player\n",
        "    # en passant - if the last move was a pawn moving up two squares, this is the space behind the square for the purposes of en passant\n",
        "    # halfmove clock - number of moves without a pawn move or piece capture, after 50 of which the game is a draw\n",
        "    # fullmove number - number of full turns starting at 1, increments after black's move\n",
        "\n",
        "    # Example FEN of starting position\n",
        "    # rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1\n",
        "    \n",
        "    parts = re.split(\" \", fen)\n",
        "    piece_placement = re.split(\"/\", parts[0])\n",
        "    active_color = parts[1]\n",
        "    castling_rights = parts[2]\n",
        "    en_passant = parts[3]\n",
        "    halfmove_clock = int(parts[4])\n",
        "    fullmove_clock = int(parts[5])\n",
        "\n",
        "    bit_vector = np.zeros((13, 8, 8), dtype=np.uint8)\n",
        "    \n",
        "    # piece to layer structure taken from reference [1]\n",
        "    piece_to_layer = {\n",
        "        'R': 1,\n",
        "        'N': 2,\n",
        "        'B': 3,\n",
        "        'Q': 4,\n",
        "        'K': 5,\n",
        "        'P': 6,\n",
        "        'p': 7,\n",
        "        'k': 8,\n",
        "        'q': 9,\n",
        "        'b': 10,\n",
        "        'n': 11,\n",
        "        'r': 12\n",
        "    }\n",
        "    \n",
        "    castling = {\n",
        "        'K': (7,7),\n",
        "        'Q': (7,0),\n",
        "        'k': (0,7),\n",
        "        'q': (0,0),\n",
        "    }\n",
        "\n",
        "    for r, row in enumerate(piece_placement):\n",
        "        c = 0\n",
        "        for piece in row:\n",
        "            if piece in piece_to_layer:\n",
        "                bit_vector[piece_to_layer[piece], r, c] = 1\n",
        "                c += 1\n",
        "            else:\n",
        "                c += int(piece)\n",
        "    \n",
        "    if en_passant != '-':\n",
        "        bit_vector[0, ord(en_passant[0]) - ord('a'), int(en_passant[1]) - 1] = 1\n",
        "    \n",
        "    if castling_rights != '-':\n",
        "        for char in castling_rights:\n",
        "            bit_vector[0, castling[char][0], castling[char][1]] = 1\n",
        "    \n",
        "    if active_color == 'w':\n",
        "        bit_vector[0, 7, 4] = 1\n",
        "    else:\n",
        "        bit_vector[0, 0, 4] = 1\n",
        "\n",
        "    if halfmove_clock > 0:\n",
        "        c = 7\n",
        "        while halfmove_clock > 0:\n",
        "            bit_vector[0, 3, c] = halfmove_clock%2\n",
        "            halfmove_clock = halfmove_clock // 2\n",
        "            c -= 1\n",
        "            if c < 0:\n",
        "                break\n",
        "\n",
        "    if fullmove_clock > 0:\n",
        "        c = 7\n",
        "        while fullmove_clock > 0:\n",
        "            bit_vector[0, 4, c] = fullmove_clock%2\n",
        "            fullmove_clock = fullmove_clock // 2\n",
        "            c -= 1\n",
        "            if c < 0:\n",
        "                break\n",
        "\n",
        "    return bit_vector\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76SVquvLkEN7",
        "outputId": "f4f58f4b-7405-4bf6-ddbc-92a68fc81627"
      },
      "outputs": [],
      "source": [
        "fen = \"rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1\"\n",
        "board = fen_to_bit_vector(fen)\n",
        "print(board)\n",
        "\n",
        "import chess\n",
        "chess.Board(fen)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JCSr6-wkEN8"
      },
      "source": [
        "O primeiro tabuleiro 8x8 (0º índice) contém todas as informações extras e os 12 tabuleiros seguintes (1 a 12) representam a localização das peças na ordem \n",
        "\n",
        "1. Torre branca\n",
        "2. Cavaleiro Branco\n",
        "3. Bispo Branco\n",
        "4. Rainha Branca\n",
        "5. Rei Branco\n",
        "6. Peão Branco\n",
        "7. Peão Preto\n",
        "8. Rei Negro\n",
        "9. Rainha Negra\n",
        "10. Bispo negro\n",
        "11. Cavaleiro Negro\n",
        "12. Torre Negra\n",
        "\n",
        "Observe como as peças se alinham corretamente com a posição inicial com o primeiro tabuleiro indicando corretamente que está na vez da branca se mover."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vf5IjQEKkEN8"
      },
      "source": [
        "# Rede Neural\n",
        "\n",
        "Começaremos com uma simples Rede Neural Feed-Forward que está totalmente conectada. As Redes Neurais são nomeadas por sua estrutura ser análoga à dos neurônios no cérebro humano. A idéia é que, no cérebro humano, quando um neurônio recebe um impulso elétrico através de suas sinapses, ele às vezes dispara um impulso elétrico para outros neurônios, criando uma reação em cadeia. Para as redes neurais, nossos neurônios são nós, nossas sinapses são bordas (com pesos correspondentes) e a queima do neurônio é a função de ativação e saída do nó. \n",
        "\n",
        "![Perceptron](http://starship-knowledge.com/wp-content/uploads/2020/10/Perceptrons-1024x724.jpeg)\n",
        "\n",
        "O objetivo da Rede Neural é ter pesos tais que, após todas as reações em cadeia dos nós que recebem entradas e produzem saídas, a saída de informações do nó final represente a avaliação da posição do xadrez que iniciou o processo. Para encontrar realmente tais pesos, usaremos um método conhecido como retropropagação, que ajusta iterativamente os pesos na rede para aproximar a saída da resposta que desejamos.\n",
        "\n",
        "Tecnicamente falando, para cada registro de treinamento (um FEN e uma avaliação) inserimos a posição na Rede Neural, e após obter um resultado, calculamos o erro entre o resultado e a avaliação correta que pode ser representada como uma função de erro. Para alterar os pesos de forma a minimizar esta função de erro, calculamos o gradiente da função de erro e ajustamos os pesos na direção oposta. Isto significa que, se excedermos, queremos diminuir nossa avaliação e, se não conseguirmos, queremos aumentar nossa avaliação.\n",
        "\n",
        "![Gradiente de descida](https://sebastianraschka.com/images/blog/2015/singlelayer_neural_networks_files/perceptron_gradient_descent_1.png)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UUqb2VIkEN9"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(832, 832)\n",
        "        self.fc2 = nn.Linear(832, 416)\n",
        "        self.fc3 = nn.Linear(416, 208)\n",
        "        self.fc4 = nn.Linear(208, 104)\n",
        "        self.fc5 = nn.Linear(104, 1)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = F.relu(self.fc4(x))\n",
        "        x = self.fc5(x)\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brRrxjBBkEN9"
      },
      "outputs": [],
      "source": [
        "# ChessDataset code and eval_to_int code taken from reference [1]\n",
        "class ChessDataset(Dataset):\n",
        "    def __init__(self, data_frame):\n",
        "        self.fens = torch.from_numpy(np.array([*map(fen_to_bit_vector, data_frame[\"FEN\"])], dtype=np.float32))\n",
        "        self.evals = torch.Tensor([[x] for x in data_frame[\"Evaluation\"]])\n",
        "        self._len = len(self.evals)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self._len\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        return self.fens[index], self.evals[index]\n",
        "\n",
        "\n",
        "def eval_to_int(evaluation):\n",
        "    try:\n",
        "        res = int(evaluation)\n",
        "    except ValueError:\n",
        "        res = 10000 if evaluation[1] == '+' else -10000\n",
        "    return res / 100\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jU5Ab8TGkEN-"
      },
      "outputs": [],
      "source": [
        "def AdamW_main(trainset, testset, batch_size, epochs, device):\n",
        "\n",
        "    print(\"Using device {}\".format(device))\n",
        "\n",
        "    print(\"Converting to pytorch Dataset...\")\n",
        "\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "    net = Net().to(device)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.AdamW(net.parameters())\n",
        "\n",
        "\n",
        "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
        "\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs, labels = data\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "                # denominator for loss should represent the number of positions evaluated \n",
        "                # independent of the batch size\n",
        "                print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / (2000*len(labels))))\n",
        "                running_loss = 0.0\n",
        "\n",
        "    print('Finished Training')\n",
        "\n",
        "    # PATH = './chess.pth'\n",
        "    # torch.save(net.state_dict(), PATH)\n",
        "\n",
        "    print('Evaluating model')\n",
        "\n",
        "    count = 0\n",
        "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            inputs, labels = data\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            #print(\"Correct eval: {}, Predicted eval: {}, loss: {}\".format(labels, outputs, loss))\n",
        "            \n",
        "            # count should represent the number of positions evaluated \n",
        "            # independent of the batch size\n",
        "            count += len(labels)\n",
        "         \n",
        "            if count % 10000 == 0:\n",
        "                print('Average error of the model on the {} tactics positions is {}'.format(count, loss/count))\n",
        "    print('Average error of the model on the {} tactics positions is {}'.format(count, loss/count))\n",
        "    return loss/count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdXc0GqCkEN_"
      },
      "outputs": [],
      "source": [
        "def SGD_main(trainset, testset, batch_size, epochs, device, learning_rate):\n",
        "    print(\"Using device {}\".format(device))\n",
        "\n",
        "    print(\"Converting to pytorch Dataset...\")\n",
        "\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "    net = Net().to(device)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.SGD(net.parameters(), lr = learning_rate)\n",
        "\n",
        "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
        "\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs, labels = data\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # print statistics\n",
        "            running_loss += loss.item()\n",
        "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "                # denominator for loss should represent the number of positions evaluated \n",
        "                # independent of the batch size\n",
        "                print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / (2000*len(labels))))\n",
        "                running_loss = 0.0\n",
        "\n",
        "    print('Finished Training')\n",
        "\n",
        "    # PATH = './chess.pth'\n",
        "    # torch.save(net.state_dict(), PATH)\n",
        "\n",
        "    print('Evaluating model')\n",
        "\n",
        "    count = 0\n",
        "    total_loss = 0\n",
        "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            inputs, labels = data\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            #print(\"Correct eval: {}, Predicted eval: {}, loss: {}\".format(labels, outputs, loss))\n",
        "            \n",
        "            # count should represent the number of positions evaluated \n",
        "            # independent of the batch size\n",
        "            count += len(labels)\n",
        "            total_loss += loss\n",
        "            if count % 10000 == 0:\n",
        "                print('Average error of the model on the {} tactics positions is {}'.format(count, loss/count))\n",
        "    print('Average error of the model on the {} tactics positions is {}'.format(count, loss/count))\n",
        "    return loss/count\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# GLOBAL VARS\n",
        "FILE_PATH='./'\n",
        "MAX_DATA = 100000\n",
        "BATCH_SIZE = 10\n",
        "EPOCHS = 10\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(\"Using device {}\".format(DEVICE))\n",
        "\n",
        "print(\"Preparing Training Data...\")\n",
        "train_data = pd.read_csv(FILE_PATH + \"chessData.csv\")\n",
        "train_data = train_data[:MAX_DATA]\n",
        "train_data[\"Evaluation\"] = train_data[\"Evaluation\"].map(eval_to_int)\n",
        "trainset = ChessDataset(train_data)\n",
        "\n",
        "print(\"Preparing Test Data...\")\n",
        "test_data = pd.read_csv(FILE_PATH + \"tactic_evals.csv\")\n",
        "test_data = test_data[:MAX_DATA]\n",
        "test_data[\"Evaluation\"] = test_data[\"Evaluation\"].map(eval_to_int)\n",
        "testset = ChessDataset(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8voN-ocE8Z88",
        "outputId": "56735a4d-251a-4f29-ac1d-c7d8f152111e"
      },
      "outputs": [],
      "source": [
        "# AdamW\n",
        "start = timer()\n",
        "AdamW = AdamW_main(trainset, testset, BATCH_SIZE, EPOCHS, DEVICE)\n",
        "end = timer()\n",
        "print('time elapsed:', timedelta(seconds=end-start))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SGD 0.01\n",
        "start = timer()\n",
        "SGD_01 = SGD_main(trainset, testset, BATCH_SIZE, EPOCHS, DEVICE, 0.01)\n",
        "end = timer()\n",
        "print('time elapsed:', timedelta(seconds=end-start))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44x554XWkEOA"
      },
      "outputs": [],
      "source": [
        "# SGD 0.001\n",
        "start = timer()\n",
        "SGD_001 = SGD_main(trainset, testset, BATCH_SIZE, EPOCHS, DEVICE, 0.001)\n",
        "end = timer()\n",
        "print('time elapsed:', timedelta(seconds=end-start))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ft_BO1EkEN-"
      },
      "source": [
        "# Resultados de AdamW\n",
        "\n",
        "Um erro médio de 0,0225 parece muito razoável, porém isto não é tão surpreendente quanto poderia parecer a princípio, já que as posições onde a avaliação do stockfish não são um par forçado, foram normalizadas para uma faixa de aproximadamente -1,5 a 1,5 e as posições onde a avaliação do stockfish é um par forçado foram definidas para -100 ou 100. Por convenção, uma pontuação positiva indica uma vantagem para o branco e uma pontuação negativa indica uma vantagem para o preto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqaMOztFkEN_"
      },
      "source": [
        "# Testando com SGD\n",
        "\n",
        "Originalmente usamos o algoritmo AdamW para a etapa de otimização, mas e se tentarmos a Descendência Estocástica Gradiente (SGD)?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToqT2gEAkEOA"
      },
      "source": [
        "Um erro médio de 0,0207 é uma ligeira melhoria, mas não tanto que possamos dizer definitivamente que o SGD fez melhor do que AdamW. Como a perda de treinamento não diminuiu muito ao longo das 10 épocas, é muito mais provável que o SGD seja um otimizador pior para este problema de classificação ou que a taxa de aprendizado seja muito grande, o que está impedindo o modelo de convergir para o ótimo local. Vamos tentar novamente, mas com uma taxa de aprendizado de 0,001"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhpZCgdzkEOA"
      },
      "source": [
        "O erro de treinamento parece estar diminuindo mesmo que esporádico, mas o erro de classificação ficou um pouco pior. Parece que o AdamW é simplesmente mais consistente e converge mais rapidamente para um ótimo local."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNpeA0kXkEOA"
      },
      "source": [
        "# Conclusão\n",
        "\n",
        "AdamW parece ser um algoritmo mais consistente e que converge mais rapidamente para um ótimo local baseado na comparação de AdamW, SGD(lr=0,01), e SGD(lr=0,001)\n",
        "\n",
        "Isto significa que o melhor modelo teve um erro médio de 0,0225, em oposição ao erro médio mais baixo de 0,0207, que não é suficientemente significativo para justificar a inconsistência do otimizador SGD."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3EYal1VkEOB"
      },
      "source": [
        "# Desafios\n",
        "\n",
        "Este conjunto de dados (ou pelo menos o conjunto de dados chessData.csv) tem mais de 16 milhões de posições e avaliações, o que torna bastante difícil trabalhar com ele. Por causa disso, tive que limitar a quantidade de dados realmente utilizada a 200.000 posições, 100.000 no conjunto de dados de treinamento e 100.000 no conjunto de dados de teste. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFtEg1g4kEOB"
      },
      "source": [
        "# Referências\n",
        "\n",
        "1. https://www.kaggle.com/ronakbadhe/chess-evaluation-prediction\n",
        "2. https://en.wikipedia.org/wiki/Forsyth%E2%80%93Edwards_Notation\n",
        "3. http://starship-knowledge.com/wp-content/uploads/2020/10/Perceptrons-1024x724.jpeg\n",
        "4. https://starship-knowledge.com/wp-content/uploads/2020/10/Perceptrons-1024x724.jpeg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GidrTuPLkEOB"
      },
      "source": [
        "# Contribution\n",
        "\n",
        "* Representation of castling rights, en passant, active color, halfmoves and fullmoves in an 8x8 grid\n",
        "* Neural Network Architecture\n",
        "* Testing AdamW vs SVG"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "chess-position-evaluator.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "8e3105560c81ae39e0834f5867d71e8b951b6beb57a3746bf5585c30fcba755d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
